#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
This script was created to generate onset files that censor *runs* with bad motion based on specified threshold
This script will reference task-foodcue_censorsummary_fd-XX.tsv, generated by 4_create_censor_files.py

Written by Bari Fuchs in Summer 2022

Copyright (C) 20120 Bari Fuchs

     This program is free software: you can redistribute it and/or modify
     it under the terms of the GNU General Public License as published by
     the Free Software Foundation, either version 3 of the License, or
     (at your option) any later version.

     This program is distributed in the hope that it will be useful,
     but WITHOUT ANY WARRANTY; without even the implied warranty of
     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
     GNU General Public License for more details.

     You should have received a copy of the GNU General Public License
     along with this program.  If not, see <https://www.gnu.org/licenses/>.
     
This script is not guaranteed to work for new data or under new directory 
configurations, however, it should work if no changes are made to directories
or raw data configurations.

@author: baf44
"""

#set up packages    
from email import header
from pickle import TRUE
from aem import con
import numpy as np
import pandas as pd
import os
from pathlib import Path
import sys, argparse
import re

##############################################################################
####                                                                      ####
####                        Set up script function                        ####
####                                                                      ####
##############################################################################


#input arguments setup
parser=argparse.ArgumentParser()
parser.add_argument('--censorsumfile', '-c', help='name of censor summary file (e.g., task-foodcue_censorsummary_fd-1.0.tsv', type=str)
parser.add_argument('--pthresh_r', '-r', help='threshold for censoring runs based on percent of TRs censored across the whole run', type=int)
parser.add_argument('--pthresh_b', '-b', help='threshold for censoring runs based on percent of TRs censored in blocks of interest', type=int)
args=parser.parse_args()


##############################################################################
####                                                                      ####
####                             Core Script                              ####
####                                                                      ####
##############################################################################

# get script location
script_path = Path(__file__).parent.resolve()

# change directory to base directory (BIDSdat) and get path
os.chdir(script_path)
os.chdir('../../..')
base_directory = Path(os.getcwd())

#set specific paths
bids_onset_path = Path(base_directory).joinpath('derivatives/preprocessed/foodcue_onsetfiles')
bids_origonset_path = Path(base_directory).joinpath('derivatives/preprocessed/foodcue_onsetfiles/orig')
bids_fmriprep_path = Path(base_directory).joinpath('derivatives/preprocessed/fmriprep')

# Import censor summary database
censorsummary_file = args.censorsumfile
censor_summary_path = Path(bids_fmriprep_path).joinpath( str(censorsummary_file))

# extract criteria used to censor TRs based on censor summary database name
substring = censorsummary_file.split("summary_",1)[1]
TR_cen_critera = substring.split(".tsv",1)[0]

if censor_summary_path.is_file(): # if database exists
    # import database
    censor_summary_allPar = pd.read_csv(str(censor_summary_path), sep = '\t')
else:
    print("censor summary file does not exist")

# subset data to remove sub 999 
censor_summary_allPar = censor_summary_allPar[censor_summary_allPar["sub"] != 999]


#########################################
#### Generate new onset timing files ####
#########################################

subs = censor_summary_allPar['sub'].unique() # get list of unique subjects to loop through

for sub in subs:

    # if thresholds are specified
    if (args.pthresh_r is not None) or (args.pthresh_b is not None):
        # set thresholds for censoring runs
        if args.pthresh_r is not None:
            p_thresh_run = args.pthresh_r

        if args.pthresh_b is not None:
            p_thresh_block = args.pthresh_b
        
        # get original onset files
        orig_onsetfiles = list(Path(bids_origonset_path).rglob('sub-' + str(sub) + '*AFNIonsets.txt'))

        # Loop through onset files (there is 1 onset file per condition)
        for onsetfile in orig_onsetfiles:

            #get filename
            filename = str(onsetfile).rsplit('/',1)[-1]

            #load file
            onsetfile_dat = pd.read_csv(str(onsetfile), sep = '\t', encoding = 'utf-8-sig', engine='python', header=None)

            # Loop through rows in onset file (row i corresponds to run i+1)
            for i in range(len(onsetfile_dat)):

                # get run number
                runnum = i + 1

                # get % of TRs censored in blocks of interest and across the run
                row = censor_summary_allPar[(censor_summary_allPar['sub'] == sub) & (censor_summary_allPar['run'] == int(runnum))] #select row based on sub and runnum
                run_p_censor_interest = int(row['p_censor_interest']) # % of TRs censored across all blocks of interest
                run_p_censor = int(row['p_censor']) # % of TRs censored across entire run

                # if censoring based on blocks of interest
                if (args.pthresh_b is not None) and (args.pthresh_r is None):

                    # if % of TRs censored across all blocks of interest in a run is > threshold
                    if run_p_censor_interest > p_thresh_block:

                        # replace column zero, row i with *
                        pd.options.mode.chained_assignment = None  # disable SettingWithCopyWarning
                        onsetfile_dat[0].iloc[i] = '*' ## gives SettingWithCopyWarning

                # if censoring based on total run only
                if (args.pthresh_b is None) and (args.pthresh_r is not None):

                    # if % of TRs censored in run (row i) is > threshold
                    if run_p_censor > p_thresh_run:

                        # replace column zero, row i with *
                        pd.options.mode.chained_assignment = None  # disable SettingWithCopyWarning
                        onsetfile_dat[0].iloc[i] = '*' ## gives SettingWithCopyWarning

                # if censoring based on total run and blocks of interest
                if (args.pthresh_b is not None) and (args.pthresh_r is not None):

                    # if % of TRs censored in across blocks of interest or in a run (row i) is > threshold
                    if run_p_censor > p_thresh_run or run_p_censor_interest > p_thresh_block:

                        # replace column zero, row i with *
                        pd.options.mode.chained_assignment = None  # disable SettingWithCopyWarning
                        onsetfile_dat[0].iloc[i] = '*' ## gives SettingWithCopyWarning

            # for subject 49, exclude run 1 due to triggering issues between scanner and eprime experiment 
            if sub == '049':
                onsetfile_dat[0].iloc[0] = '*'

            #######################################
            #### Output new onset timing files ####
            #######################################
            
            # set path to onset directory

            # if thresholding based on blocks only
            if (args.pthresh_b is not None) and (args.pthresh_r is None):
                new_onset_path = Path(bids_onset_path).joinpath(str(TR_cen_critera) + "_b" + str(p_thresh_block))

            # if thresholding based on runs only
            elif (args.pthresh_r is not None) and (args.pthresh_b is None):
                new_onset_path = Path(bids_onset_path).joinpath(str(TR_cen_critera) + "_r" + str(p_thresh_run))

            # if thresholding based on block and run
            elif (args.pthresh_r is not None) and (args.pthresh_b is not None):  
                new_onset_path = Path(bids_onset_path).joinpath(str(TR_cen_critera) + "_r" + str(p_thresh_run) + '_b' + str(p_thresh_block))

            # Check whether the onset directory exists or not
            isExist = os.path.exists(new_onset_path)
            if not isExist:
                # make new path
                os.makedirs(new_onset_path)
            
            # write file
            onsetfile_dat.to_csv(str(Path(new_onset_path).joinpath(filename)), sep = '\t', encoding='utf-8-sig', index = False, header=False)