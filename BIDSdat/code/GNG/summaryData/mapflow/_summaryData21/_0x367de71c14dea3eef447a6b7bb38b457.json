[
    [
        "GNG_file",
        [
            "/Users/azp271/OneDrive - The Pennsylvania State University/b-childfoodlab_Shared/Active_Studies/RO1_Brain_Mechanisms_IRB_5357/Participant_Data/BIDSdat/raw_data/sub-036/ses-1/beh/sub-036_ses-1_task-gng_events.tsv",
            "cfb0c071b33c2e805414b5ca6060bbce"
        ]
    ],
    [
        "function_str",
        "def summaryGNG(GNG_file):\n    import numpy as np\n    import pandas as pd\n    from scipy.stats import norm\n\n    ###################################################################\n    ####                   Sub-function script                     ####\n\n    #need to write sub-functions (e.g., getGNGtrialAcc) WITHIN the function that is called by the node (e.g., summaryGNG)\n    #just like you need to re-import libraries\n\n    def getGNGtrialAcc(GNG_data):\n        #Make 2 new variables:\n        #trial_resp: indicate if response made during trial (stim or response screen)\n        #trial_rt: indicate reaction time from onset of stim screen (add 750 ms to respond_rt if response occured during response screen)\n\n        #initialize empty columns for trial_resp and trial_rt\n        GNG_data[\"trial_resp\"] = np.nan\n        GNG_data[\"trial_rt\"] = np.nan\n\n        #Assign values to trial_resp and trial_rt\n        GNG_data.loc[GNG_data.stim_resp == '{SPACE}', 'trial_resp'] = '{SPACE}'\n        GNG_data.loc[GNG_data.respond_resp == '{SPACE}', 'trial_resp'] = '{SPACE}'\n        GNG_data.loc[GNG_data.stim_resp == '{SPACE}', 'trial_rt'] = GNG_data.stim_rt\n        GNG_data.loc[GNG_data.respond_resp == '{SPACE}', 'trial_rt'] = GNG_data.respond_rt + 750\n\n        ##Create new accuracy variable \"Acc_Resp\" that indicates a 1 when the columns 'CorrectResp' and 'RESP' match\n        #initialize empty columns for accuracy variable\n        GNG_data[\"trial_acc\"] = np.nan\n\n        # Change nan to none because pandas/NumPy uses the fact that np.nan != np.nan\n        GNG_data[['ca', 'trial_resp']] = GNG_data[['ca', 'trial_resp']].fillna(value='None')\n\n        # Set accuracy equal to 1 when ca = trial_resp\n        GNG_data['trial_acc'] = np.where(GNG_data['trial_resp'] == GNG_data['ca'], '1', '0')\n\n        return(GNG_data)\n\n    def summary_stats(GNG_data):\n\n        # Create 2 dataframes, one with Go trials and one with No Go trials\n        Go_data = GNG_data.loc[GNG_data['compatibility'] == 'Go']\n        NoGo_data = GNG_data.loc[GNG_data['compatibility'] == 'NoGo']\n\n        # count trials\n        nGo = len(Go_data)\n        nNoGo = len(NoGo_data)\n\n        # Accuracy\n        nAcc = GNG_data[GNG_data.trial_acc == '1'].shape[0]\n        pAcc = nAcc/len(GNG_data)\n\n        # Go Hits/Misses\n        nGo_Hit = (Go_data.trial_acc == '1').sum()\n        pGo_Hit = nGo_Hit/len(Go_data)\n\n        nGo_Miss = (Go_data.trial_acc == '0').sum()\n        pGo_Miss = nGo_Miss/len(Go_data)\n\n        #NoGo Commissions (False Alarms) and Correct no responses  \n        nNoGo_Corr = (NoGo_data.trial_acc == '1').sum()\n        pNoGo_Corr = nNoGo_Corr/len(NoGo_data)\n\n        nNoGo_FA = (NoGo_data.trial_acc == '0').sum()\n        pNoGo_FA = nNoGo_FA/len(NoGo_data)\n\n        # Mean and median RT\n        RTmeanGo_Hit = Go_data.loc[(Go_data['trial_acc']==\"1\"), 'trial_rt'].mean()\n        RTmedGo_Hit = Go_data.loc[(Go_data['trial_acc']==\"1\"), 'trial_rt'].median()\n\n        RTmeanNoGo_FA = NoGo_data.loc[(NoGo_data['trial_acc']==\"0\"), 'trial_rt'].mean()\n        RTmedNoGo_FA = NoGo_data.loc[(NoGo_data['trial_acc']==\"0\"), 'trial_rt'].median()\n\n        ####  Compute signal detection theory metrics ####\n        #get z-score for hit and false alarm rates\n        #add adjustments for extreme values because norm.ppf of 0/1 is -inf/inf\n        z_Hit = norm.ppf(pGo_Hit)\n        z_FA = norm.ppf(pNoGo_FA)\n\n        #do Macmillian adjustments for extreme values: if hit rate = 1, new hit\n        #rate = (nGo - 0.5)/nGo; if false alarm rate = 0, new false alarm rate\n        #= 0.5/nNoGo. If no extreme value, then just save standard calculation\n        #for z in that place\n\n        if pGo_Hit == 1:\n            pHit_mm = (nGo - 0.5)/nGo\n            z_Hit_mm = norm.ppf(pHit_mm)\n        else:\n            pHit_mm = pGo_Hit\n            z_Hit_mm = norm.ppf(pHit_mm)\n\n        if pNoGo_FA == 0:\n            pFA_mm = 0.5/nNoGo\n            z_FA_mm = norm.ppf(pFA_mm)\n        else:\n            pFA_mm = pNoGo_FA\n            z_FA_mm = norm.ppf(pFA_mm)\n\n        #do loglinear adjustments: add 0.5 to NUMBER of hits and FA and add 1\n        #to number of Go and NoGo trials. Then caluculate z off of new hit and\n        #FA rates\n        nHit_ll = nGo_Hit + 0.5\n        nGo_ll = nGo + 1\n        nFA_ll = nNoGo_FA + 0.5\n        nNoGo_ll = nNoGo + 1\n        pHit_ll = nHit_ll/nGo_ll\n        pFA_ll = nFA_ll/nNoGo_ll\n        z_Hit_ll = norm.ppf(pHit_ll)\n        z_FA_ll = norm.ppf(pFA_ll)\n\n        #calculate sensory sensitivity d'\n        d_prime_mm = z_Hit_mm - z_FA_mm\n        d_prime_ll = z_Hit_ll - z_FA_ll\n\n        #calculate nonparametric sensory sensitivity A':\n        #0.5+[sign(H-FA)*((H-FA)^2 + |H-FA|)/(4*max(H, FA) - 4*H*FA))\n        A_prime_mm = 0.5 + np.sign(pHit_mm-pFA_mm)*(((pHit_mm-pFA_mm)**2+abs(pHit_mm - pFA_mm))/(4*max(pHit_mm, pFA_mm) - 4*pHit_mm*pFA_mm))\n        A_prime_ll = 0.5 + np.sign(pHit_ll-pFA_ll)*(((pHit_ll-pFA_ll)**2+abs(pHit_ll - pFA_ll))/(4*max(pHit_ll, pFA_ll) - 4*pHit_ll*pFA_ll))\n\n        #calculate c (criterion)\n        c_mm = (norm.ppf(pHit_mm) + norm.ppf(pFA_mm))/2\n        c_ll = (norm.ppf(pHit_ll) + norm.ppf(pFA_ll))/2\n\n        #calculate Grier's Beta--beta\", a nonparametric response bias\n        Grier_beta_mm = np.sign(pHit_mm-pFA_mm)*((pHit_mm*(1-pHit_mm)-pFA_mm*(1-pFA_mm))/(pHit_mm*(1-pHit_mm)+pFA_mm*(1-pFA_mm)))\n        Grier_beta_ll = np.sign(pHit_ll-pFA_ll)*((pHit_ll*(1-pHit_ll)-pFA_ll*(1-pFA_ll))/(pHit_ll*(1-pHit_ll)+pFA_ll*(1-pFA_ll)))\n\n        #combine into array    \n        summary_results = [nGo, nNoGo, nAcc, pAcc, nGo_Hit, nGo_Miss, nNoGo_Corr, nNoGo_FA, pGo_Hit, \n                           pGo_Miss, pNoGo_Corr, pNoGo_FA, RTmeanGo_Hit, RTmeanNoGo_FA, RTmedGo_Hit, RTmedNoGo_FA,\n                           z_Hit, z_FA, z_Hit_mm, z_FA_mm, z_Hit_ll, z_FA_ll, d_prime_mm, d_prime_ll, A_prime_mm,\n                           A_prime_ll, c_mm, c_ll, Grier_beta_mm, Grier_beta_ll]\n\n        return(summary_results)\n\n    ###################################################################\n    ####                Primary function script                    ####\n\n    if isinstance(GNG_file, str):\n        if '.tsv' in GNG_file:\n            #if only 1 file, will be string and we want an array\n            GNG_file = [GNG_file]\n        else:\n            GNG_file = []\n\n    if len(GNG_file) > 0:\n\n        #loop counter\n        count = 0\n\n        for file in GNG_file:\n\n            #load data - loop throgh participant blockfiles\n            GNG_data = pd.read_csv(str(file), sep = '\\t', encoding = 'utf-8-sig', engine='python') \n\n            #check for incomplete blocks\n            block_counts = GNG_data['block_list_sample'].value_counts()\n            to_remove = block_counts[block_counts < 40].index\n\n            if len(to_remove) > 0:\n                GNG_data = GNG_data[~GNG_data.block_list_sample.isin(to_remove)]\n\n            # Compute GNG trial accuracy and rt\n            GNG_data = getGNGtrialAcc(GNG_data)\n\n            # Set column names\n            colnames = ['sub', 'block', 'nGo', 'nNoGo', 'nAcc', 'pAcc', 'nGo_Hit', 'nGo_Miss', 'nNoGo_Corr',  'nNoGo_FA', 'pGo_Hit', 'pGo_Miss', 'pNoGo_Corr', 'pNoGo_FA', 'RTmeanGo_Hit', 'RTmeanNoGo_FA', 'RTmedGo_Hit', 'RTmedNoGo_FA', 'z_Hit', 'z_FA', 'z_Hit_mm', 'z_FA_mm', 'z_Hit_ll', 'z_FA_ll', 'd_prime_mm',  'd_prime_ll','A_prime_mm', 'A_prime_ll', 'c_mm', 'c_ll', 'Grier_beta_mm', 'Grier_beta_ll']\n\n            #summary stats - across all blocks\n            all_trials_stat = summary_stats(GNG_data)\n            all_trials_stat.insert(0, GNG_data.loc[0, 'sub'])\n            all_trials_stat.insert(1, 'all')\n\n            if count == 0:\n                #make dataset\n                overall_summary_data = pd.DataFrame(all_trials_stat).T\n                overall_summary_data.columns = colnames\n            else:\n                overall_summary_data.loc[len(overall_summary_data)] = all_trials_stat\n\n            #summary stats by block\n\n            #get all non-duplicate blocks in dataset\n            blocks = GNG_data['block_list_sample'].unique()\n\n            #loop through blocks\n            for b in blocks:\n\n                #subset block data from GNG_data\n                b_data = GNG_data[GNG_data['block_list_sample'] == b]\n\n                #ensure block_cond column is string\n                b_data = b_data.convert_dtypes()\n\n                #set block variable name\n                b_var = (\"b\" + str(int(b)))\n\n                # Get summary stats for block\n                block_summary = summary_stats(b_data)\n                block_summary.insert(0, GNG_data.loc[0, 'sub'])\n                block_summary.insert(1, b_var)\n\n                #append new rows\n                overall_summary_data.loc[len(overall_summary_data)] = block_summary\n\n            #update count for files loop\n            count = 1\n\n    else:\n         overall_summary_data = 'no files'\n\n    return overall_summary_data\n"
    ]
]