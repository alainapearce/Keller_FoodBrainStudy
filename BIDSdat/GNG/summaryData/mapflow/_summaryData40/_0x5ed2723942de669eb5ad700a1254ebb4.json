[
    [
        "GNG_file",
        [
            "/Users/azp271/OneDrive - The Pennsylvania State University/b-childfoodlab_Shared/Active_Studies/RO1_Brain_Mechanisms_IRB_5357/Participant_Data/BIDSdat/raw_data/sub-037/ses-1/beh/sub-037_ses-1_task-gng_events.tsv",
            "bc7b5ab06164a45ae0ceb19176f56e43"
        ]
    ],
    [
        "function_str",
        "def summaryGNG(GNG_file):\n    import numpy as np\n    import pandas as pd\n\n    ###################################################################\n    ####                   Sub-function script                     ####\n\n    #need to write sub-functions (e.g., getGNGtrialAcc) WITHIN the function that is called by the node (e.g., summaryGNG)\n    #just like you need to re-import libraries\n\n    def getGNGtrialAcc(GNG_data):\n        #Make 2 new variables:\n        #trial_resp: indicate if response made during trial (stim or response screen)\n        #trial_rt: indicate reaction time from onset of stim screen (add 750 ms to respond_rt if response occured during response screen)\n\n        #initialize empty columns for trial_resp and trial_rt\n        GNG_data[\"trial_resp\"] = np.nan\n        GNG_data[\"trial_rt\"] = np.nan\n\n        #Assign values to trial_resp and trial_rt\n        GNG_data.loc[GNG_data.stim_resp == '{SPACE}', 'trial_resp'] = '{SPACE}'\n        GNG_data.loc[GNG_data.respond_resp == '{SPACE}', 'trial_resp'] = '{SPACE}'\n        GNG_data.loc[GNG_data.stim_resp == '{SPACE}', 'trial_rt'] = GNG_data.stim_rt\n        GNG_data.loc[GNG_data.respond_resp == '{SPACE}', 'trial_rt'] = GNG_data.respond_rt + 750\n\n        ##Create new accuracy variable \"Acc_Resp\" that indicates a 1 when the columns 'CorrectResp' and 'RESP' match\n        #initialize empty columns for accuracy variable\n        GNG_data[\"trial_acc\"] = np.nan\n\n        # Change nan to none because pandas/NumPy uses the fact that np.nan != np.nan\n        GNG_data[['ca', 'trial_resp']] = GNG_data[['ca', 'trial_resp']].fillna(value='None')\n\n        # Set accuracy equal to 1 when trial_acc = trial_resp\n        GNG_data['trial_acc'] = np.where(GNG_data['trial_resp'] == GNG_data['ca'], '1', '0')\n\n        return(GNG_data)\n\n    def summary_stats(GNG_data):\n\n        # Create 2 dataframes, one with Go trials and one with No Go trials\n        Go_data = GNG_data.loc[GNG_data['compatibility'] == 'Go']\n        NoGo_data = GNG_data.loc[GNG_data['compatibility'] == 'NoGo']\n\n        # count trials\n        nGo = len(Go_data)\n        nNoGo = len(NoGo_data)\n\n        # Accuracy - here *check par 51\n        if 1 in GNG_data.trial_acc:\n            nAcc = GNG_data['trial_acc'].value_counts()[\"1\"]\n        else: \n            nAcc = 0\n\n        pAcc = nAcc/len(GNG_data)\n\n        # Go Hits/Misses\n        nGo_Hit = (Go_data.trial_acc == '1').sum()\n        pGo_Hit = nGo_Hit/len(Go_data)\n\n        nGo_Miss = (Go_data.trial_acc == '0').sum()\n        pGo_Miss = nGo_Miss/len(Go_data)\n\n        #NoGo Commissions (False Alarms) and Correct no responses  \n        nNoGo_Corr = (NoGo_data.trial_acc == '1').sum()\n        pNoGo_Corr = nNoGo_Corr/len(NoGo_data)\n\n        nNoGo_FA = (NoGo_data.trial_acc == '0').sum()\n        pNoGo_FA = nNoGo_FA/len(NoGo_data)\n\n        # Mean and median RT\n        RTmeanGo_Hit = Go_data.loc[(Go_data['trial_acc']==\"1\"), 'trial_rt'].mean()\n        RTmedGo_Hit = Go_data.loc[(Go_data['trial_acc']==\"1\"), 'trial_rt'].median()\n\n        RTmeanNoGo_FA = NoGo_data.loc[(NoGo_data['trial_acc']==\"0\"), 'trial_rt'].mean()\n        RTmedNoGo_FA = NoGo_data.loc[(NoGo_data['trial_acc']==\"0\"), 'trial_rt'].median()\n\n        #combine into array    \n        summary_results = [nGo, nNoGo, nAcc, pAcc, nGo_Hit, nGo_Miss, nNoGo_Corr, nNoGo_FA, pGo_Hit, \n                           pGo_Miss, pNoGo_Corr, pNoGo_FA, RTmeanGo_Hit, RTmeanNoGo_FA, RTmedGo_Hit, RTmedNoGo_FA]\n\n        return(summary_results)\n\n    ## DDM\n    #RT data at different quantils # this is a separate database thats output.\n    # Can always skip this for now, and make note to make DDM function\n    # SDT = signal detection theory. google norminv, it gives z-score. should be able to ask for norminv in python\n\n    ###################################################################\n    ####                Primary function script                    ####\n\n    if isinstance(GNG_file, str):\n        if '.tsv' in GNG_file:\n            #if only 1 file, will be string and we want an array\n            GNG_file = [GNG_file]\n        else:\n            GNG_file = []\n\n    if len(GNG_file) > 0:\n\n        #loop counter\n        count = 0\n\n        for file in GNG_file:\n\n            #load data - loop throgh participant blockfiles\n            GNG_data = pd.read_csv(str(file), sep = '\\t', encoding = 'utf-8-sig', engine='python') \n\n            #check for incomplete blocks\n            block_counts = GNG_data['block_list_sample'].value_counts()\n            to_remove = block_counts[block_counts < 40].index\n\n            if len(to_remove) > 0:\n                GNG_data = GNG_data[~GNG_data.block_list_sample.isin(to_remove)]\n\n            # Compute GNG trial accuracy and rt\n            GNG_data = getGNGtrialAcc(GNG_data)\n\n            # Set column names\n            colnames = ['sub', 'block', 'nGo', 'nNoGo', 'nAcc', 'pAcc', 'nGo_Hit', 'nGo_Miss', 'nNoGo_Corr', \n                        'nNoGo_FA', 'pGo_Hit', 'pGo_Miss', 'pNoGo_Corr', 'pNoGo_FA', 'RTmeanGo_Hit',\n                        'RTmeanNoGo_FA', 'RTmedGo_Hit', 'RTmedNoGo_FA']\n\n            #summary stats - across all blocks\n            all_trials_stat = summary_stats(GNG_data)\n            all_trials_stat.insert(0, GNG_data.loc[0, 'sub'])\n            all_trials_stat.insert(1, 'all')\n\n            if count == 0:\n                #make dataset\n                overall_summary_data = pd.DataFrame(all_trials_stat).T\n                overall_summary_data.columns = colnames\n            else:\n                overall_summary_data.loc[len(overall_summary_data)] = all_trials_stat\n\n            #summary stats by block\n\n            #get all non-duplicate blocks in dataset\n            blocks = GNG_data['block_list_sample'].unique()\n\n            #loop through blocks\n            for b in blocks:\n\n                #subset block data from GNG_data\n                b_data = GNG_data[GNG_data['block_list_sample'] == b]\n\n                #ensure block_cond column is string\n                b_data = b_data.convert_dtypes()\n\n                #set block variable name\n                b_var = (\"b\" + str(int(b)))\n\n                # Get summary stats for block\n                block_summary = summary_stats(b_data)\n                block_summary.insert(0, GNG_data.loc[0, 'sub'])\n                block_summary.insert(1, b_var)\n\n                #append new rows\n                overall_summary_data.loc[len(overall_summary_data)] = block_summary\n\n            #update count for files loop\n            count = 1\n\n    else:\n         overall_summary_data = 'no files'\n\n    return overall_summary_data\n"
    ],
    [
        "needed_outputs",
        [
            "summaryGNG_dat"
        ]
    ]
]