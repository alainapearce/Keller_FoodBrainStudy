[
    [
        "SST_file",
        [
            "/Users/azp271/OneDrive - The Pennsylvania State University/b-childfoodlab_Shared/Active_Studies/RO1_Brain_Mechanisms_IRB_5357/Participant_Data/BIDSdat/raw_data/sub-103/ses-1/beh/sub-103_ses-1_task-sst_events.tsv",
            "731626c9bb0bd757a2299891f4a03bca"
        ]
    ],
    [
        "function_str",
        "def summarySST(SST_file):\n    import numpy as np\n    import pandas as pd\n\n    ###################################################################\n    ####                   Sub-function script                     ####\n\n    #need to sub-functions within the function that is called by the node just \n    #like you need to re-import libraries\n    def summary_stats(SST_data):\n\n        ## ANALYSIS NOTE: \n        ## the original version of ANALYZE_IT and recommendations were to remove\n        ## the first trial of each block. However, this is not reccomended in the\n        ## concensus article Verbruggen et al., 2019 or in the new ANALYZE-IT-Tscope.R\n        ## code on Open Science Foundation (https://osf.io/dw4ke/). \n\n        ## to remove first trial of each block, uncomment below code:\n\n        #drop first row of each block\n        #if 1 in SST_data['block']:\n        #    block1 = SST_data.loc[SST_data['block'] == 1].index.values\n        #    SST_data = SST_data.drop(block1[0])\n        #    \n        #if 2 in SST_data['block']:\n        #    block2 = SST_data.loc[SST_data['block'] == 2].index.values\n        #    SST_data = SST_data.drop(block2[0])\n        #    \n        #if 3 in SST_data['block']:\n        #    block3 = SST_data.loc[SST_data['block'] == 3].index.values\n        #    SST_data = SST_data.drop(block3[0])\n        # \n        #if 4 in SST_data['block']:\n        #    block4 = SST_data.loc[SST_data['block'] == 4].index.values\n        #    SST_data = SST_data.drop(block4[0])\n\n        #trial counts\n        SST_target = SST_data.groupby('stop_signal').get_group(0)\n        SST_stop = SST_data.groupby('stop_signal').get_group(1)\n\n        #trial counts\n        sst_n_targets = SST_target.shape[0]\n        sst_n_stop = SST_stop.shape[0]\n        sst_go_correct = SST_target[SST_target['correct'] == 4].shape[0]\n        sst_go_error = SST_target[SST_target['correct'] == 2].shape[0]\n        sst_go_miss = SST_target[SST_target['correct'] == 1].shape[0]\n\n        #rt \n        go_rt = SST_target.loc[SST_target['rt_1'] > 0, 'rt_1'].mean(axis = 0)    \n        go_rt_correct = SST_target.loc[(SST_target['correct'] == 4) & (SST_target['rt_1'] > 0), 'rt_1'].mean(axis = 0)\n        go_rt_error = SST_target.loc[(SST_target['correct'] == 2) & (SST_target['rt_1'] > 0), 'rt_1'].mean(axis = 0)\n\n        us_rt = SST_stop.loc[(SST_stop['correct'] == 3) & (SST_stop['rt_1'] > 0), 'rt_1'].mean(axis = 0)\n\n        #probability of responding on signal  -- p(resp|signal)\n        signal_presp = SST_stop.loc[(SST_stop['correct'] == 3)].shape[0]/sst_n_stop\n\n        #SSD\n        ssd = SST_stop['true_ssd'].mean(axis = 0)\n\n        #racehorse check\n        if go_rt > us_rt:\n            racehorse = 1\n        else:\n            racehorse = 0\n\n        if racehorse == 1:\n\n            #SSRT Mean methods\n            ssrt_mean = SST_target.loc[SST_target['correct'] != 1, 'rt_1'].mean(axis = 0) - ssd\n\n            #SSRT Integration method\n            #replace omissions with max RT if there are omissions\n            if sst_go_miss > 0:\n                #get max rt\n                max_rt = max(SST_target.loc[SST_target['correct'] != 1, 'rt_1'])\n\n                #make new dataset\n                SST_target_replace = SST_target\n\n                #supress warning\n                pd.options.mode.chained_assignment = None\n\n                #replace ommitted rt values\n                SST_target_replace.loc[SST_target_replace['correct'] == 1, 'rt_1'] = max_rt\n\n                #get rt at signal_presp percentile\n                nth_rt = np.percentile(SST_target_replace['rt_1'], 100*signal_presp)\n\n            else:\n                #get rt at signal_presp percentile\n                nth_rt = np.percentile(SST_target['rt_1'], 100*signal_presp)\n\n\n            #caluclate ssrt\n            ssrt_int = nth_rt - ssd\n\n        else:\n            ssrt_mean = np.nan\n            ssrt_int = np.nan\n\n\n        #combine into array    \n        summary_results = [racehorse, sst_n_stop, sst_n_targets, go_rt, sst_go_correct, go_rt_correct, \n                         sst_go_error, go_rt_error, sst_go_miss, signal_presp, us_rt,\n                         ssd, ssrt_mean, ssrt_int]\n\n        return(summary_results)\n\n    ###################################################################\n    ####                Primary function script                    ####\n\n    if isinstance(SST_file, str):\n        #check to see if it is filepath str or 'No subfiles' message\n        if '.tsv' in SST_file:\n            #if only 1 file, will be string and we want an array\n            SST_file = [SST_file]\n        else:\n            SST_file = []\n\n    if len(SST_file) > 0:\n\n        #loop counter\n        count = 0\n\n        for file in SST_file:\n\n            #load data - loop throgh participant blockfiles\n            SST_ProcData = pd.read_csv(str(file), sep = '\\t', encoding = 'utf-8-sig', engine='python') \n\n            #check for incomplete blocks\n            block_counts = SST_ProcData['block'].value_counts()\n            to_remove = block_counts[block_counts < 64].index\n\n            if len(to_remove) > 0:\n                SST_ProcData = SST_ProcData[~SST_ProcData.block.isin(to_remove)]\n\n            #check for duplicate conditions - coding error in initial task randomization\n            cond_list = SST_ProcData.groupby('block')['block_cond'].unique()\n\n            #convert to strings\n            cond_list = [str(item[0]) for item in cond_list]\n            unique_cond = np.unique(cond_list)\n\n            #if there are duplicate blocks, re-label second instance\n            if len(unique_cond) < len(cond_list):\n                for cond in unique_cond:\n                    cond_group = SST_ProcData.groupby('block_cond').get_group(cond)\n\n                    #number of blocks with condition 'cond'\n                    nblocks = len(cond_group['block'].unique())\n\n                    if nblocks > 1:\n                        #get block number for second instance of cond\n                        dup_block = max(cond_group['block'])\n\n                        #for rows where column 'block' = dup_block, replace column 'block_cond'\n                        #values\n                        SST_ProcData.loc[SST_ProcData['block'] == dup_block, 'block_cond'] = SST_ProcData[SST_ProcData['block'] == dup_block]['block_cond'].replace(cond, 'dup_' + cond)\n\n            #remove duplicate blocks\n            SST_nodup_blocks = SST_ProcData[SST_ProcData['block_cond'].str.contains('dup')==False]\n\n            colnames = ['sub', 'block', 'condition', 'racehorse_check', 'n_stop_trials', 'n_go_trials', 'go_rt', 'n_go_cor', 'go_cor_rt', 'n_go_error',\n                'go_error_rt', 'n_go_miss', 'stop_prob_resp', 'us_rt', 'ssd', 'ssrt_mean', 'ssrt_int']\n\n            #summary stats - across all blocks\n            all_trials_stat = summary_stats(SST_nodup_blocks)\n            all_trials_stat.insert(0, SST_ProcData.loc[0, 'sub'])\n            all_trials_stat.insert(1, 'all')\n            all_trials_stat.insert(2, 'all')\n\n            if count == 0:\n                #make dataset\n                overall_summary_data = pd.DataFrame(all_trials_stat).T\n                overall_summary_data.columns = colnames\n            else:\n                overall_summary_data.loc[len(overall_summary_data)] = all_trials_stat\n\n            # summary stats - by block conditions\n\n            #check is there are 2 high ED blocks and 2 low ED blocks\n            hed_blocks = [item for item in unique_cond if 'hED' in item]\n            led_blocks = [item for item in unique_cond if 'lED' in item]\n\n            #ensure block_cond column is string\n            SST_nodup_blocks = SST_nodup_blocks.convert_dtypes()\n\n            if len(hed_blocks) == 2 and len(led_blocks) == 2:\n                #high ED data\n                SST_hed_blocks = SST_nodup_blocks[SST_nodup_blocks['block_cond'].str.contains('hED')]\n\n                hed_trials_stat = summary_stats(SST_hed_blocks)\n                hed_trials_stat.insert(0, SST_ProcData.loc[0, 'sub'])\n                hed_trials_stat.insert(1, 'h_ed')\n                hed_trials_stat.insert(2, 'h_ed')\n\n                #append new rows\n                overall_summary_data.loc[len(overall_summary_data)] = hed_trials_stat\n\n                #low ED data\n                SST_led_blocks = SST_nodup_blocks[SST_nodup_blocks['block_cond'].str.contains('lED')]\n\n                led_trials_stat = summary_stats(SST_led_blocks) \n                led_trials_stat.insert(0, SST_ProcData.loc[0, 'sub'])\n                led_trials_stat.insert(1, 'l_ed')\n                led_trials_stat.insert(2, 'l_ed')\n\n                #append new rows\n                overall_summary_data.loc[len(overall_summary_data)] = led_trials_stat\n\n            #check is there are 2 large portion blocks and 2 small portion blocksa\n            lport_blocks = [item for item in unique_cond if 'lPort' in item]\n            sport_blocks = [item for item in unique_cond if 'sPort' in item]\n\n            if len(lport_blocks) == 2 and len(sport_blocks) == 2:\n                #large portion data\n                SST_lport_blocks = SST_nodup_blocks[SST_nodup_blocks['block_cond'].str.contains('lPort')]\n\n                lport_trials_stat = summary_stats(SST_lport_blocks)\n                lport_trials_stat.insert(0, SST_ProcData.loc[0, 'sub'])\n                lport_trials_stat.insert(1, 'l_port')\n                lport_trials_stat.insert(2, 'l_port')\n\n                #append new rows\n                overall_summary_data.loc[len(overall_summary_data)] = lport_trials_stat\n\n\n                #small portion\n                SST_sport_blocks = SST_nodup_blocks[SST_nodup_blocks['block_cond'].str.contains('sPort')]\n\n                sport_trials_stat = summary_stats(SST_sport_blocks)\n                sport_trials_stat.insert(0, SST_ProcData.loc[0, 'sub'])\n                sport_trials_stat.insert(1, 's_port')\n                sport_trials_stat.insert(2, 's_port')\n\n                #append new rows\n                overall_summary_data.loc[len(overall_summary_data)] = sport_trials_stat\n\n            #summary stats by block\n\n            #get all non-duplicate blocks in dataset\n            blocks = SST_nodup_blocks['block'].unique()\n\n            #loop through blocks\n            for b in blocks:\n                #block data\n                b_data = SST_nodup_blocks[SST_nodup_blocks['block'] == b]\n\n                #ensure block_cond column is string\n                b_data = b_data.convert_dtypes()\n\n                #high ED, large portion\n                if b_data['block_cond'].str.contains('hED_lPort').any():\n\n                    hED_lPort_stat = summary_stats(b_data)\n                    hED_lPort_stat.insert(0, SST_ProcData.loc[0, 'sub'])\n                    hED_lPort_stat.insert(1, b)\n                    hED_lPort_stat.insert(2, 'hED_lPort')   \n\n                    #append new rows\n                    overall_summary_data.loc[len(overall_summary_data)] = hED_lPort_stat\n\n                #high ED, small portion        \n                elif b_data['block_cond'].str.contains('hED_sPort').any():\n\n                    hED_sPort_stat = summary_stats(b_data)\n                    hED_sPort_stat.insert(0, SST_ProcData.loc[0, 'sub'])\n                    hED_sPort_stat.insert(1, b)\n                    hED_sPort_stat.insert(2, 'hED_sPort')  \n\n                    #append new rows\n                    overall_summary_data.loc[len(overall_summary_data)] = hED_sPort_stat\n\n                #low ED, large portion\n                elif b_data['block_cond'].str.contains('lED_lPort').any():\n\n                    lED_lPort_stat = summary_stats(b_data)\n                    lED_lPort_stat.insert(0, SST_ProcData.loc[0, 'sub'])\n                    lED_lPort_stat.insert(1, b)\n                    lED_lPort_stat.insert(2, 'lED_lPort') \n\n                    #append new rows\n                    overall_summary_data.loc[len(overall_summary_data)] = lED_lPort_stat\n\n\n                #low ED, small portion\n                elif b_data['block_cond'].str.contains('lED_sPort').any():\n\n                    lED_sPort_stat = summary_stats(b_data)\n                    lED_sPort_stat.insert(0, SST_ProcData.loc[0, 'sub'])\n                    lED_sPort_stat.insert(1, b)\n                    lED_sPort_stat.insert(2, 'lED_sPort')\n\n                    #append new rows\n                    overall_summary_data.loc[len(overall_summary_data)] = lED_sPort_stat\n\n            #update count for files loop\n            count = 1\n\n    else:\n         overall_summary_data = 'no files'\n\n\n    return overall_summary_data\n"
    ],
    [
        "needed_outputs",
        [
            "summarySST_dat"
        ]
    ]
]