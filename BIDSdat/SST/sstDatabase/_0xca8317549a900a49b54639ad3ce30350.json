[('SST_summary_dat', [   sub   block  condition racehorse_check  ...    us_rt      ssd ssrt_mean ssrt_int
0  114     all        all               1  ...  439.594  223.188   326.456  319.312
1  114    h_ed       h_ed               1  ...  465.312  223.969    290.75  266.531
2  114    l_ed       l_ed               1  ...  413.875  222.406   362.531  367.094
3  114  l_port     l_port               1  ...  486.357    224.5   303.906      268
4  114  s_port     s_port               1  ...  403.222  221.875    349.23  375.438
5  114       1  hED_lPort               1  ...  498.286  179.188   309.792  277.938
6  114       2  hED_sPort               1  ...  439.667   268.75   271.708  274.125
7  114       3  lED_sPort               1  ...  366.778      175   427.404  461.688
8  114       4  lED_lPort               1  ...  474.429  269.812   298.021      251

[9 rows x 17 columns]]), ('bids_dir', '/Users/azp271/OneDrive - The Pennsylvania State University/b-childfoodlab_Shared/Active_Studies/RO1_Brain_Mechanisms_IRB_5357/Participant_Data/BIDSdat'), ('function_str', "def updateDatabase_save(SST_summary_dat, overwrite_flag, bids_dir):\n    import pandas as pd\n    import numpy as np\n    from pathlib import Path\n    from nipype.interfaces.base import Bunch\n\n    #get a Bunch object if more than 1 participant \n    if isinstance(SST_summary_dat, Bunch):        \n        #get output data from node\n        SST_summary_datlist = SST_summary_dat.summarySST_dat\n\n        #combine datasets \n        SST_summary_dat = pd.concat(SST_summary_datlist)\n\n    #if only 1 participant/dataset then it is a list    \n    elif isinstance(SST_summary_dat, list):\n        if len(SST_summary_dat) == 1:\n            SST_summary_dat = SST_summary_dat[0]\n        else:\n            SST_summary_dat = pd.concat(SST_summary_dat)\n\n    #if a pandas dataframe\n    if isinstance(SST_summary_dat, pd.DataFrame):\n\n        #get column names\n        columnnames = SST_summary_dat.columns\n\n        #get condition subset\n        SST_summary_conds = SST_summary_dat[SST_summary_dat.block.isin(['all', 'h_ed', 'l_ed', 'l_port', 's_port'])]\n\n        #make wide data set \n        SST_summary_wide = SST_summary_conds.pivot(columns='condition', index='sub', values=columnnames[3:17])        \n        SST_summary_wide.columns = ['_'.join(col) for col in SST_summary_wide.columns.reorder_levels(order=[1, 0])]\n\n        #make the sub index into a dataset column\n        SST_summary_wide = SST_summary_wide.reset_index(level = 0)\n\n        #re-order columns\n        columnnames_reorder = ['sub', 'all_racehorse_check', \n                               'all_n_stop_trials', 'all_n_go_trials', 'all_go_rt', \n                               'all_n_go_cor', 'all_go_cor_rt', 'all_n_go_error',  \n                               'all_go_error_rt', 'all_n_go_miss', 'all_stop_prob_resp',\n                               'all_us_rt', 'all_ssd', 'all_ssrt_mean', 'all_ssrt_int', \n                               'h_ed_racehorse_check', 'h_ed_n_stop_trials',\n                               'h_ed_n_go_trials', 'h_ed_go_rt', 'h_ed_n_go_cor', \n                               'h_ed_go_cor_rt', 'h_ed_n_go_error',\n                               'h_ed_go_error_rt', 'h_ed_n_go_miss', 'h_ed_stop_prob_resp', \n                               'h_ed_us_rt', 'h_ed_ssd', 'h_ed_ssrt_mean', 'h_ed_ssrt_int',\n                               'l_ed_racehorse_check', 'l_ed_n_stop_trials', 'l_ed_n_go_trials', \n                               'l_ed_go_rt', 'l_ed_n_go_cor', 'l_ed_go_cor_rt', \n                               'l_ed_n_go_error', 'l_ed_go_error_rt', 'l_ed_n_go_miss', \n                               'l_ed_stop_prob_resp', 'l_ed_us_rt', 'l_ed_ssd',\n                               'l_ed_ssrt_mean', 'l_ed_ssrt_int', 'l_port_racehorse_check', \n                               'l_port_n_stop_trials', 'l_port_n_go_trials', 'l_port_go_rt', \n                               'l_port_n_go_cor', 'l_port_go_cor_rt', 'l_port_n_go_error',\n                               'l_port_go_error_rt', 'l_port_n_go_miss', 'l_port_stop_prob_resp', \n                               'l_port_us_rt', 'l_port_ssd', 'l_port_ssrt_mean', 'l_port_ssrt_int',\n                               's_port_racehorse_check', 's_port_n_stop_trials',\n                               's_port_n_go_trials', 's_port_go_rt', 's_port_n_go_cor', \n                               's_port_go_cor_rt', 's_port_n_go_error',\n                               's_port_go_error_rt', 's_port_n_go_miss', 's_port_stop_prob_resp', \n                               's_port_us_rt', 's_port_ssd', 's_port_ssrt_mean', 's_port_ssrt_int']\n\n        SST_summary_wide = SST_summary_wide.reindex(columns=columnnames_reorder)\n\n        #get blocks subset\n        SST_summary_blocks = SST_summary_dat[SST_summary_dat.condition.isin(['hED_lPort', 'hED_sPort', 'lED_lPort', 'lED_sPort'])] \n\n        ## load databases\n        #derivative data path\n        derivative_data_path = Path(bids_dir).joinpath('derivatives/preprocessed/beh')\n\n        #load databases\n        SST_database_cond = pd.read_csv(str(Path(derivative_data_path).joinpath('task-sst_summary_condwide.tsv')), sep = '\\t') \n        SST_database_blocks = pd.read_csv(str(Path(derivative_data_path).joinpath('task-sst_summary_blockslong.tsv')), sep = '\\t')\n\n        #if overwriting participants\n        if overwrite_flag == True:\n            #function to drop rows based on values\n            def filter_rows_by_values(df, col, values):\n                return df[df[col].isin(values) == False]\n\n            #get list of subs to filter in wide and long data\n            wide_sub_list = list(SST_summary_wide['sub'].unique())\n            block_sub_list = list(SST_summary_blocks['sub'].unique())\n\n            #filter out/remove exisiting subs to overwrite\n            SST_database_cond = filter_rows_by_values(SST_database_cond, 'sub', wide_sub_list)\n            SST_database_blocks = filter_rows_by_values(SST_database_blocks, 'sub', block_sub_list)\n\n        #add newly processed data\n        SST_database_cond = SST_database_cond.append(SST_summary_wide)\n        SST_database_blocks = SST_database_blocks.append(SST_summary_blocks)\n\n        #sort to ensure in sub order\n        SST_database_cond = SST_database_cond.sort_values(by = 'sub')\n        SST_database_blocks = SST_database_blocks.sort_values(by = ['sub', 'block'])\n\n        #round to 3 decimal points\n        SST_database_cond = SST_database_cond.applymap(lambda x: round(x, 3) if isinstance(x, (int, float)) else x)\n        SST_database_blocks = SST_database_blocks.applymap(lambda x: round(x, 3) if isinstance(x, (int, float)) else x)\n\n        #write databases\n        SST_database_cond.to_csv(str(Path(derivative_data_path).joinpath('task-sst_summary_condwide.tsv')), sep = '\\t', encoding='utf-8-sig', index = False) \n        SST_database_blocks.to_csv(str(Path(derivative_data_path).joinpath('task-sst_summary_blockslong.tsv')), sep = '\\t', encoding='utf-8-sig', index = False)\n\n    else:\n        print('No raw data files that need to be processed')\n        SST_database_cond = np.nan\n        SST_database_blocks = np.nan\n\n    return SST_database_cond, SST_database_blocks\n"), ('overwrite_flag', False)]